{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import requests as rq\n",
    "import sys\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.callbacks\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "df = pd.read_json('News_Category_Dataset_v2.json', lines=True)\n",
    "headlines = df.headline.tolist()\n",
    "text=\"\"\n",
    "#clean the data into individual sentences\n",
    "\n",
    "for headline in headlines[:5000]:\n",
    "    text=text+\" \"+headline[0:len(headline)]+'.'\n",
    "\n",
    "# avg_len = sum( map(len, headlines) ) / len(headlines)\n",
    "# avg_len\n",
    "text = text[1:]\n",
    "text[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Week 5 Lab\n",
    "\n",
    "# storing all unique characters\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "# breaking the data into sentences of length seqlen\n",
    "seqlen = 100\n",
    "step = seqlen\n",
    "sentences = []\n",
    "for i in range(0, len(text) - seqlen - 1, step):\n",
    "    sentences.append(text[i: i + seqlen])\n",
    "\n",
    "# setting up the data to be trained by the LSTM Model\n",
    "\n",
    "x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "\n",
    "# Model below\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "    preds = preds / np.sum(preds)                #\n",
    "    probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "    return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "    \n",
    "    # Using a high diversity\n",
    "\n",
    "    for diversity in [0.8, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + seqlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1\n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            next_index = sample(preds[0, -1], diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = df.headline.tolist()\n",
    "sentences_2=[]\n",
    "text2=\"\"\n",
    "\n",
    "total_avg = sum( map(len, headlines) ) / len(headlines)\n",
    "avg_len_of_sen=int(total_avg)\n",
    "\n",
    "for headline in headlines:\n",
    "    if len(headline) == avg_len_of_sen:\n",
    "        sentences_2.append(headline[0:len(headline)])\n",
    "        text2=text2+\" \"+headline[0:len(headline)]\n",
    "# text = text[1:]\n",
    "#text[1:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chars1 = sorted(list(set(text2)))\n",
    "char_indices1 = dict((c, i) for i, c in enumerate(chars1))\n",
    "indices_char1 = dict((i, c) for i, c in enumerate(chars1))\n",
    "\n",
    "\n",
    "seqlen1 = avg_len_of_sen\n",
    "step1 = seqlen1\n",
    "\n",
    "x = np.zeros((len(sentences_2), seqlen1, len(chars1)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences_2), seqlen1, len(chars1)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences_2):\n",
    "    for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "        x[i, t, char_indices1[char_in]] = 1\n",
    "        y[i, t, char_indices1[char_out]] = 1\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(128, input_shape=(seqlen1, len(chars1)), return_sequences=True))\n",
    "model1.add(Dense(len(chars1), activation='softmax'))\n",
    "\n",
    "model1.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam', #RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "    preds = preds / np.sum(preds)                #\n",
    "    probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "    return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "def on_epoch_end1(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    rand_index = random.randint(0, len(sentences_2) - 1)\n",
    "    \n",
    "    # Q5: What does diversity do?\n",
    "    for diversity in [0.8, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = sentences_2[rand_index]\n",
    "        #sentence=''\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(avg_len_of_sen*4):\n",
    "            x_pred = np.zeros((1, seqlen1, len(chars1)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices1[char]] = 1.\n",
    "            \n",
    "            preds1 = model1.predict(x_pred, verbose=0)\n",
    "            next_index = sample(preds1[0, -1], diversity)\n",
    "            next_char = indices_char1[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end1)\n",
    "\n",
    "model1.fit(x, y,\n",
    "          batch_size=60,\n",
    "          epochs=50,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = df.headline.tolist()\n",
    "sentences3=[]\n",
    "\n",
    "for headline in headlines:\n",
    "    sentences3.append(headline[0:len(headline)])\n",
    "\n",
    "sentences3[:200]\n",
    "subset_sentences = sentences3[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.utils as ku \n",
    "\n",
    "# set seeds for reproducability\n",
    "from tensorflow.random import set_seed\n",
    "from numpy.random import seed\n",
    "set_seed(2)\n",
    "seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "## tokenization\n",
    "\n",
    "tokenizer.fit_on_texts(subset_sentences)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "## convert data to sequence of tokens\n",
    "\n",
    "in_sequences = []\n",
    "for line in subset_sentences:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        sequence = token_list[:i+1]\n",
    "        in_sequences.append(sequence)\n",
    "\n",
    "in_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(x) for x in in_sequences])\n",
    "in_sequences = np.array(pad_sequences(in_sequences, maxlen=max_sequence_len, padding='pre'))   \n",
    "X, y = in_sequences[:,:-1],in_sequences[:,-1]\n",
    "y = ku.to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN LSTM model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 10, input_length=max_sequence_len - 1))\n",
    "model.add(LSTM(100))\n",
    "\n",
    "# optional\n",
    "\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=10, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_headlines(seed_text, headline_len, model, max_sequence_len):\n",
    "    for _ in range(headline_len):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, i in tokenizer.word_index.items():\n",
    "            if i == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "trends=[]\n",
    "\n",
    "URL = \"https://twitter-trends.iamrohit.in/united-states\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(id=\"copyData\")\n",
    "rows = results.find_all('tr')\n",
    "for row in rows:\n",
    "    cols=row.find_all('th')\n",
    "    cols=[x.text for x in cols]\n",
    "    if len(cols) > 2:\n",
    "        trend = cols[1].split('\\n')[0]\n",
    "        if trend[0] == '#':\n",
    "            trends.append(trend[1:-1])\n",
    "        else:\n",
    "            trends.append(trend[:-1])\n",
    "trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news=[]\n",
    "headline_len = 10\n",
    "for trend in trends:\n",
    "    print(generate_headlines(trend, headline_len, model, max_sequence_len).title())\n",
    "    fake_news.append(generate_headlines(trend, headline_len, model, max_sequence_len).title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
